swagger: '2.0'
info:
  title: argos-api-v1
  description: ' <img src=''https://www.scitility.com/wp-content/uploads/2025/07/C_green_circle_4_scitilityBlue_medium-300x85.png''
    width=''150px'' /> <p>Argos API has been built from the ground up as a modern
    API-First Scientific Integrity platform. All our capabilities will be exposed
    as Public APIs to customers that have a plan that include API Access. Argos can
    be integrated in your tools and workflows via this API. </p> <p>In this document
    you can find documentation about the available endpoints as well as usage examples.</p>
    <p>The Argos API follows the best practices of REST API design. You should expect
    every endpoint, parameter and return field documented in here to be stable. We
    will NOT remove them or change their semantic until we release a new major version
    of the API and we will give you enough time to transition to it. You should expect
    this API to get new endpoints, new parameters and new return fields (API expansion)
    on the current version and therefore your code should ignore unknown properties
    when deserializing our responses. </p> '
  version: 1.0.0
schemes:
- https
host: argos-api-gateway-9xt5ivdc.nw.gateway.dev
securityDefinitions:
  api_key:
    type: apiKey
    name: x-api-key
    in: header
    description: Scitility provided API Key to access our services via APIs. This
      is a unique and secret key that we should have generated only for you. If you
      do not have one, please reach us at hello@scitility.com or read about our offering
      at https://www.scitility.com
security:
- api_key: []
paths:
  /argos/api/v1/author:
    get:
      tags:
      - author profiles
      description: Search of retracted authors that are indexed in Argos
      operationId: author-search
      parameters:
      - name: search
        in: query
        description: 'Search criteria in the format ''key:value''. Multiple criteria
          are comma-separated. We support the following criteria:<br /> <ul> <li>name
          (required): Author name (can be partial, eg: Johnson). Restrict the results
          to profiles that belong to an author with a name that fuzzily match your
          search criteria. Minimum Name length is 4 characters.</li>  <li>institution
          (optional): Author Affiliation Institution name (can be partial, eg: Harvard).
          Restrict the results to profiles that have an affiliation to that institution.</li>
          </ul>

          '
        required: true
        type: string
        example: name:Moslem Lari,institution:Kerman University
      produces:
      - application/json
      responses:
        200:
          description: A successful search has been performed. See the data section
            for results.
          schema:
            $ref: '#/definitions/MultipleAuthorProfileResponse'
          examples:
            application/json:
              metadata:
                timestamp: '2025-01-05T23:54:34.217184506Z'
                parameters:
                  name: Moslem Lari
                  institution: Kerman University
                resultCount: 1
              data:
              - bestMatchingName: Moslem Lari Najafi
                authorProfile:
                  ids:
                    openAlexId: https://openalex.org/A5081680860
                    orcid: https://orcid.org/0000-0002-4170-2792
                  displayName: Moslem Lari Najafi
                  displayNameAlternatives:
                  - M. L. Najafi
                  - Moslem Najafi
                  - Moslem Lari Najafi
                  institutions:
                  - Kerman University of Medical Sciences
                  - Sabzevar University of Medical Sciences
                  worksCount: 55
                  citedByCount: 706
                  hIndex: 16.0
                  retractedWorksCount: 1
                  retractedWorks:
                  - title: Method of Cumulative Anomaly Identification for Security
                      Database Based on Discrete Markov chain
                    journal: Security and Communication Networks
                    publisher: Hindawi
                    authors:
                    - Zhiying Xu
                    - Ting Yang
                    - Moslem Lari Najafi
                    originalPaperDoi: https://doi.org/10.1155/2022/5113725
                    retractionDoi: https://doi.org/10.1155/2023/9831958
                    originalPaperDate: '2022-03-21'
                    retractionDate: '2023-12-06'
                    retractionNature: Retraction
                    reasons:
                    - Fake Peer Review
                    - Investigation by Journal/Publisher
                    - Investigation by Third Party
                    - Paper Mill
                    - Unreliable Results
                    notes: ''
                    source: Retraction Watch
                    highRisk: true
        400:
          description: 'Bad request. Please check you have specified a name with at
            least 4 characters. Eg: /author?search=name:Victoria

            '
          schema:
            $ref: '#/definitions/Test40xresponse'
        401:
          $ref: '#/responses/Unauthorized'
  /argos/api/v1/author/openalexid/{openalexid}:
    get:
      tags:
      - author profiles
      description: Given an abbreviated author OpenAlex Id, returns an author profile
        and all the retractions found for it
      operationId: author-by-openalexid
      produces:
      - application/json
      parameters:
      - in: path
        name: openalexid
        type: string
        required: true
        description: Abbreviated Open Alex ID that identifies the author you want
          to query. Eg A5000578396. The abbreviated id is the final substring from
          OpenAlex author identifier (https://openalex.org/authors/A5000578396 OR
          https://openalex.org/A5000578396 should both be represented as A5000578396)
      responses:
        200:
          description: Response with the Author profile found or null
          schema:
            $ref: '#/definitions/SingleAuthorProfileResponse'
          examples:
            application/json:
              metadata:
                timestamp: '2025-01-03T15:44:38.772302528Z'
                parameters:
                  openAlexId: A5000578396
                resultCount: 1
              data:
                ids:
                  openAlexId: https://openalex.org/A5000578396
                  orcid: https://orcid.org/0000-0002-6131-2118
                displayName: Muhammad Usman
                displayNameAlternatives:
                - M. Usman
                - Muhammad Usman
                - Muhammad Zahid Usman
                institutions:
                - Wuhan University
                - Government College University, Faisalabad
                - University of Leeds
                - Riphah International University
                - Huazhong University of Science and Technology
                - University of Agriculture Faisalabad
                - University of Management and Technology
                - University of the Punjab
                - University of Faisalabad
                - Capital University of Science and Technology
                worksCount: 146
                citedByCount: 8778
                hIndex: 52.0
                retractedWorksCount: 1
                retractedWorks:
                - title: 'The role of monetary and fiscal policies in determining
                    environmental pollution: Revisiting the N-shaped EKC hypothesis
                    for China'
                  journal: Environmental Science and Pollution Research
                  publisher: Springer
                  authors:
                  - Tang Zhengxia
                  - Mohammad Haseeb
                  - Muhammad Usman
                  - Mohd Shuaib
                  - Mustafa Kamal
                  - Mohammad Faisal Khan
                  originalPaperDoi: https://doi.org/10.1007/s11356-023-28672-w
                  retractionDoi: https://doi.org/10.1007/s11356-024-33020-7
                  originalPaperDate: '2023-07-17'
                  retractionDate: '2024-03-26'
                  retractionNature: Retraction
                  reasons:
                  - Author Unresponsive
                  - Concerns/Issues About Results
                  - Concerns/Issues about Referencing/Attributions
                  - Fake Peer Review
                  - Investigation by Journal/Publisher
                  - Randomly Generated Content
                  - Unreliable Results
                  notes: ''
                  source: Retraction Watch
                  highRisk: true
        404:
          description: We have been unable to find an author profile associated with
            the OpenAlex ID.
        401:
          $ref: '#/responses/Unauthorized'
  /argos/api/v1/author/orcid/{orcid}:
    get:
      tags:
      - author profiles
      description: Given an author abbreviated Orcid, returns an author profile and
        all the retractions found for it
      operationId: author-by-orcid
      produces:
      - application/json
      parameters:
      - in: path
        name: orcid
        type: string
        required: true
        description: Abbreviated Orcid that identifies the author you want to query,
          without including the https://orcig.org prefix. Eg 0000-0002-1825-0097.
          The abbreviated id is the final substring of an Orcid (https://orcid.org/0000-0002-1825-0097
          should be represented as 0000-0002-1825-0097)
      responses:
        200:
          description: We have found an author profile associated with the Orcid.
            The data section contains the author profile which carries the retractions
            associated with it (if there is any).
          schema:
            $ref: '#/definitions/SingleAuthorProfileResponse'
          examples:
            application/json:
              metadata:
                timestamp: '2025-09-01T12:19:17.548158191Z'
                parameters:
                  orcid: 0000-0002-5883-8119
                resultCount: 1
              data:
                ids:
                  openAlexId: https://openalex.org/A5057906344
                  orcid: https://orcid.org/0000-0002-5883-8119
                displayName: "M. \u041C. Tanashyan"
                displayNameAlternatives:
                - "M Tanashyan \u2010"
                - Marine Tanashyan
                - M. M Tanashyan
                - Marine M. Tanashyan
                - "\u041Carine \u041C. Tanashyan"
                - M. M. Tanashyan
                - Tanashyan Mm
                - M. Tanashyan
                - "M. \u041C. Tanashyan"
                - Marine Movsesovna Tanashyan
                - "Marine \u041C. Tanashyan"
                - M.M. Tanashyan Tanashyan
                - Tanashian
                - Tanashian, M.M.
                - Tanashyan, Marine M.
                - Tanyashjan
                - Tanyashjan, M.M.
                - Tanashan
                - "\u0422\u0430\u043D\u0430\u0448\u044F\u043D, \u041C.\u041C."
                institutions:
                - Research Center of Neurology
                - Thales (Portugal)
                - ORCID
                - Academy of Medical Sciences
                - Laboratory Imaging (Czechia)
                - Neurological Surgery
                - Russian Academy of Sciences
                - Angion (United States)
                - Krasnoyarsk State Medical University
                worksCount: 239
                citedByCount: 670
                hIndex: 10.0
                retractedWorksCount: 1
                retractedWorks:
                - title: Microrheological disorders in patients with polycythemia
                    vera suffered acute ischemic stroke
                  journal: Molecular and Cellular Biochemistry
                  publisher: Springer
                  authors:
                  - Marine Tanashyan
                  - Alla Shabalina
                  - Eugene Roitman
                  originalPaperDoi: https://doi.org/10.1007/s11010-021-04352-6
                  retractionDoi: https://doi.org/10.1007/s11010-024-04973-7
                  originalPaperDate: '2022-01-04'
                  retractionDate: '2024-03-02'
                  retractionNature: Retraction
                  reasons:
                  - Concerns/Issues About Authorship/Affiliation
                  - Concerns/Issues with Peer Review
                  - Investigation by Journal/Publisher
                  - Unreliable Results and/or Conclusions
                  notes: ''
                  source: Retraction Watch
                  highRisk: true
        404:
          description: We have been unable to find an author profile associated with
            the Orcid.
        401:
          $ref: '#/responses/Unauthorized'
  /argos/api/v1/authors/orcid/{orcid}:
    get:
      tags:
      - author profiles
      description: Given multiple authors abbreviated Orcid separated by commas, returns
        multiple author profiles (if found) and all the retractions found for it
      operationId: authors-by-orcid
      produces:
      - application/json
      parameters:
      - in: path
        name: orcid
        type: string
        required: true
        description: Abbreviated Orcids separated by commas that identify the authors
          you want to query, without including the https://orcig.org prefix. Eg 0000-0002-1825-0097.
          The abbreviated id is the final substring of an Orcid (https://orcid.org/0000-0002-1825-0097
          should be represented as 0000-0002-1825-0097)
      responses:
        200:
          description: We have found an author profile associated with the Orcid.
            The data section contains the author profile which carries the retractions
            associated with it (if there is any).
          schema:
            $ref: '#/definitions/SingleAuthorProfileResponse'
          examples:
            application/json:
              metadata:
                timestamp: '2025-09-01T12:19:17.548158191Z'
                parameters:
                  orcid: 0000-0002-5883-8119
                resultCount: 1
              data:
                ids:
                  openAlexId: https://openalex.org/A5057906344
                  orcid: https://orcid.org/0000-0002-5883-8119
                displayName: "M. \u041C. Tanashyan"
                displayNameAlternatives:
                - "M Tanashyan \u2010"
                - Marine Tanashyan
                - M. M Tanashyan
                - Marine M. Tanashyan
                - "\u041Carine \u041C. Tanashyan"
                - M. M. Tanashyan
                - Tanashyan Mm
                - M. Tanashyan
                - "M. \u041C. Tanashyan"
                - Marine Movsesovna Tanashyan
                - "Marine \u041C. Tanashyan"
                - M.M. Tanashyan Tanashyan
                - Tanashian
                - Tanashian, M.M.
                - Tanashyan, Marine M.
                - Tanyashjan
                - Tanyashjan, M.M.
                - Tanashan
                - "\u0422\u0430\u043D\u0430\u0448\u044F\u043D, \u041C.\u041C."
                institutions:
                - Research Center of Neurology
                - Thales (Portugal)
                - ORCID
                - Academy of Medical Sciences
                - Laboratory Imaging (Czechia)
                - Neurological Surgery
                - Russian Academy of Sciences
                - Angion (United States)
                - Krasnoyarsk State Medical University
                worksCount: 239
                citedByCount: 670
                hIndex: 10.0
                retractedWorksCount: 1
                retractedWorks:
                - title: Microrheological disorders in patients with polycythemia
                    vera suffered acute ischemic stroke
                  journal: Molecular and Cellular Biochemistry
                  publisher: Springer
                  authors:
                  - Marine Tanashyan
                  - Alla Shabalina
                  - Eugene Roitman
                  originalPaperDoi: https://doi.org/10.1007/s11010-021-04352-6
                  retractionDoi: https://doi.org/10.1007/s11010-024-04973-7
                  originalPaperDate: '2022-01-04'
                  retractionDate: '2024-03-02'
                  retractionNature: Retraction
                  reasons:
                  - Concerns/Issues About Authorship/Affiliation
                  - Concerns/Issues with Peer Review
                  - Investigation by Journal/Publisher
                  - Unreliable Results and/or Conclusions
                  notes: ''
                  source: Retraction Watch
                  highRisk: true
        404:
          description: We have been unable to find an author profile associated with
            the Orcid.
        401:
          $ref: '#/responses/Unauthorized'
  /argos/api/v1/doi/{shortDoi=**}:
    get:
      description: Retrieves the information about the DOI that is held by Argos.
        We will return the latest information that has been collected by our data
        pipelines, including article metadata, retractions, expressions of concern,
        etc.
      operationId: doi
      parameters:
      - in: path
        name: shortDoi
        type: string
        required: true
        description: 'Short DOI, excluding the protocol prefix (https), the host (doi.org)
          and any port information. Example: 10.1016/j.segan.2022.100905

          '
      produces:
      - application/json
      tags:
      - doi
      responses:
        200:
          description: Successful response that carries the information known by Argos
            about the requested DOI
          schema:
            type: object
            properties:
              utcResponseTime:
                type: string
                format: date-time
                description: The UTC timestamp of when the response was generated.
              doi:
                type: string
                format: uri
                description: The DOI of the article being queried.
              title:
                type: string
                description: The title of the article.
              publicationDate:
                type: string
                format: date
                description: The date the DOI was published.
              authors:
                type: array
                description: Authorship and affiliation information
                items:
                  type: object
                  properties:
                    name:
                      type: string
                      description: The name of the author.
                    affiliation:
                      type: array
                      items:
                        type: object
                        properties:
                          name:
                            type: string
                            description: The name of the institution or organization
                              the author is affiliated with.
                          rorId:
                            type: string
                            format: uri
                            description: The ROR (Research Organization Registry)
                              ID of the author's affiliation.
                    identifiers:
                      type: object
                      properties:
                        orcid:
                          type: string
                          format: uri
                          description: The ORCID of the author.
              articleSource:
                type: object
                description: Source where the DOI has been published
                properties:
                  name:
                    type: string
                    description: The name of the journal or publication where the
                      article was published.
                  type:
                    type: string
                    description: The type of the source (e.g., 'journal').
              publisher:
                type: string
                description: The publisher of the article.
              isRetracted:
                type: boolean
                description: Indicates if the article has been retracted.
              isRetractionNote:
                type: boolean
                description: Indicates if this response is a retraction note itself.
                  Note that some publishers use the original DOI of the article as
                  a Retraction DOI in which case you should expect both isRetracted
                  and isRetractionNote booleans to be true.
              records:
                type: array
                description: 'Array of records related to this DOI. Records can contain
                  retractions, expressions of concern or other updates. At the moment
                  we are only returning the most recent record related to the DOI
                  that has been queried.

                  '
                items:
                  type: object
                  properties:
                    type:
                      type: string
                      description: The type of record (e.g., 'Retraction').
                    publicationDate:
                      type: string
                      format: date
                      description: The date the record was published. If the record
                        is of type 'Retraction', this date should be understood as
                        the Retraction Date.
                    reasons:
                      type: array
                      items:
                        type: string
                      description: The reasons for retraction.
                    refersToDoi:
                      type: string
                      format: uri
                      description: The DOI that this retraction refers to.
                    recordDoi:
                      type: string
                      format: uri
                      description: The DOI of the retraction record itself.
                    recordSource:
                      type: string
                      description: The source of the retraction record (e.g., 'Retraction
                        Watch').
              riskAssessment:
                type: object
                description: Argos Risk Assessment. Currently based on authorship
                  retraction history and retracted references (feet of clay).
                properties:
                  riskCategory:
                    type: string
                    description: The category of risk assigned. Possible values are
                      'low', 'medium', 'high' or 'none' for DOIs where a risk assessment
                      is not applicable (already retracted articles, retraction notes,
                      etc.).
                  authorshipRecordHistory:
                    type: array
                    description: History of retractions, expressions of concerns and
                      other relevant updates associated with the authors of this DOI.
                    items:
                      type: object
                      properties:
                        authorDisplayName:
                          type: string
                          description: The display name of the author.
                        historicalRecord:
                          type: array
                          description: Details of retraction records associated with
                            this author.
                          items:
                            type: object
                            properties:
                              type:
                                type: string
                                description: The type of record, for example, 'Retraction',
                                  'Expression of concern', 'Withdrawal'.
                              publicationDate:
                                type: string
                                format: date
                                description: The date when the record was published.
                              refersToDoi:
                                type: string
                                format: uri
                                description: The DOI of the paper to which this record
                                  refers.
                              recordDoi:
                                type: string
                                format: uri
                                description: The DOI of the record itself.
                  retractedReferences:
                    type: array
                    description: List of references that have been retracted and are
                      associated with this DOI.
                    items:
                      type: object
                      properties:
                        originalPaperDoi:
                          type: string
                          format: uri
                          description: The DOI of the original paper that has been
                            retracted and that is referenced by the requested DOI.
          examples:
            application/json:
              utcResponseTime: '2025-03-04T15:13:45.034988503'
              doi: https://doi.org/10.1016/j.jclinane.2020.109727
              title: 'RETRACTED: Transnasal humidified rapid-insufflation ventilatory
                exchange can be utilized in tracheal stenosis caused by thyroid tumor'
              publicationDate: '2020-01-15'
              authors:
              - name: Hironobu Ueshima
                affiliation:
                - name: Showa University Hospital
                  rorId: https://ror.org/04wn7d698
                identifiers:
                  orcid: https://orcid.org/0000-0002-2533-1178
              - name: Takahiro Goda
                affiliation:
                - name: Showa University Hospital
                  rorId: https://ror.org/04wn7d698
                identifiers:
                  orcid: https://orcid.org/0000-0003-4196-5389
              - name: Hiroshi Otake
                affiliation:
                - name: Showa University Hospital
                  rorId: https://ror.org/04wn7d698
                identifiers:
                  orcid: https://orcid.org/0000-0002-4776-3211
              articleSource:
                name: Journal of Clinical Anesthesia
                type: journal
              publisher: Elsevier BV
              isRetracted: true
              isRetractionNote: false
              records:
              - type: Retraction
                publicationDate: '2022-02-09'
                reasons:
                - False/Forged Authorship
                - Misconduct by Author
                refersToDoi: https://doi.org/10.1016/j.jclinane.2020.109727
                recordDoi: https://doi.org/10.1016/j.jclinane.2022.110785
                recordSource: Scitility
              riskAssessment:
                riskCategory: none
                authorshipRecordHistory:
                - authorDisplayName: John Smith
                  historicalRecord:
                  - type: Retraction
                    publicationDate: '2024-11-13'
                    refersToDoi: https://doi.org/10.12345/123456-789
                    recordDoi: https://doi.org/10.12345/s41598-024-78897-z
                  - type: Retraction
                    publicationDate: '2024-01-29'
                    refersToDoi: https://doi.org/10.12345/12070597
                    recordDoi: https://doi.org/10.12345/16020191
                retractedReferences:
                - originalPaperDoi: https://doi.org/10.3390/pharmaceutics12080761
        400:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'INVALID_ARGUMENT: API key not valid. Please pass a valid API
                key.

                '
              code: 400
        401:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'UNAUTHENTICATED: Method doesn''t allow unregistered callers
                (callers without established identity). Please use API Key or other
                form of API consumer identity to call this API.

                '
              code: 401
        404:
          description: "DOI not found. There can be several reasons for this:\n  -\
            \ The article was published before Jan 2014. We only analyse articles\
            \ from this date.\n  - The article has been very recently published and\
            \ we don't have the data yet.\n  - The DOI does not exist.\n"
          schema:
            $ref: '#/definitions/Test404response'
          examples:
            application/json:
              message: Unable to find DOI https://doi.org/not-existing
  /argos/api/v1/reference-section:
    post:
      tags:
      - reference analysis
      summary: Analyze the reference section of a scientific article
      description: "This operation allows users to analyze the references of a scientific\
        \ article by providing the entire reference section as a plain text input.\
        \ \nThe analysis includes checking if each reference is retracted, has an\
        \ expression of concern, is a retraction note, \nand evaluates its risk level.\n"
      operationId: reference-section
      requestBody:
        description: A reference section (plain text in one big string)
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                referenceSection:
                  type: string
                  description: The reference section to analyse. Provide each reference
                    in a new line (split by \n).
                  example: "1. Ashouri, M., Zarei, M.M. and Moosavi, A. (2022), \"\
                    Investigation of the effects of geometrical parameters, eccentricity\
                    \ and perforated fins on natural convection heat transfer in a\
                    \ finned horizontal annulus using three dimensional lattice Boltzmann\
                    \ flux solver\", International Journal of Numerical Methods for\
                    \ Heat & Fluid Flow, Vol. 32 No. 1, pp. 283- 312. https://doi.org/10.1108/HFF-10-2020-0629\
                    \ \n2. Sowmya, G., B.J., G., Khan, M.I., Momani, S. and Hayat,\
                    \ T. (2020), \"RETRACTED: Thermal investigation of fully wet longitudinal\
                    \ porous fin of functionally graded material\", International\
                    \ Journal of Numerical Methods for Heat & Fluid Flow, Vol. 30\
                    \ No. 12, pp. 5087-5101. https://doi.org/10.1108/HFF-12-2019-0908\
                    \ \n3. Koulali, A., Zi\xF3\u0142kowski, P., Radomski, P., De Sio,\
                    \ L., Zieli\u0144ski, J., Nev\xE1rez Mart\xEDnez, M.C. and Mikielewicz,\
                    \ D. (2025), \"Analysis of heat transfer and AuNPs-mediated photo-thermal\
                    \ inactivation of E. coli at varying laser powers using single-phase\
                    \ CFD modeling\", International Journal of Numerical Methods for\
                    \ Heat & Fluid Flow, Vol. 35 No. 1, pp. 382- 413. \n4. Elshehabey,\
                    \ H.M. (2024), \"Predicting heat transfer rate and system entropy\
                    \ based on combining artificial neural network with numerical\
                    \ simulation\", International Journal of Numerical Methods for\
                    \ Heat & Fluid Flow, Vol. 34 No. 6, pp. 2480-2512."
      responses:
        200:
          description: A successful reference analysis
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/definitions/ReferenceAnalysisResponse'
          examples:
            application/json:
            - referenceDoi: https://doi.org/example-doi-1
              doiFound: true
              likelyHallucinated: false
              analysis:
                isRetracted: true
                hasExpressionOfConcern: false
                isRetractionNote: false
                isHighRisk: false
                isMediumRisk: false
            - referenceDoi: https://doi.org/example-doi-2
              doiFound: true
              likelyHallucinated: false
              analysis:
                isRetracted: false
                hasExpressionOfConcern: false
                isRetractionNote: false
                isHighRisk: false
                isMediumRisk: true
            - referenceDoi: https://doi.org/non-existing-doi
              doiFound: false
              likelyHallucinated: true
              analysis: null
        400:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'INVALID_ARGUMENT: API key not valid. Please pass a valid API
                key.

                '
              code: 400
        401:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'UNAUTHENTICATED: Method doesn''t allow unregistered callers
                (callers without established identity). Please use API Key or other
                form of API consumer identity to call this API.

                '
              code: 401
  /argos/api/v1/tortured-phrases:
    post:
      tags:
      - full text analysis
      summary: Analyze the full text of a scientific article and return a list of
        phrases that are considered to be "tortured phrases".
      description: "This analysis is useful to identify non sensical papers created\
        \ by non sophisticated researchers. \nFor more information about the analysis,\
        \ please refer to the original paper: https://arxiv.org/pdf/2107.06751\n"
      operationId: tortured-phrases
      requestBody:
        description: A fulltext article (plain text in one big string)
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                fulltext:
                  type: string
                  description: The full text of the article to analyse (plain text).
                  example: "Pneumonia Detection in Chest X-Ray Images Using Enhanced\
                    \ Restricted Boltzmann Machine\nFazli Wahid, Sania Azhar, Sikandar\
                    \ Ali, Muhammad Sultan Zia, Faisal Abdulaziz Almisned, Abdu Gumaei\n\
                    First published: 12 August 2022\nhttps://doi.org/10.1155/2022/1678000\n\
                    Citations: 1\nAcademic Editor: Vincenzo Positano\n\nAbstract\n\
                    The process of pneumonia detection has been the focus of researchers\
                    \ as it has proved itself to be one of the most dangerous and\
                    \ life-threatening disorders. In recent years, many machine learning\
                    \ and deep learning algorithms have been applied in an attempt\
                    \ to automate this process but none of them has been successful\
                    \ significantly to achieve the highest possible accuracy. In a\
                    \ similar attempt, we propose an enhanced approach of a deep learning\
                    \ model called restricted Boltzmann machine (RBM) which is named\
                    \ enhanced RBM (ERBM). One of the major drawbacks associated with\
                    \ the standard format of RBM is its random weight initialization\
                    \ which leads to improper feature learning of the model during\
                    \ the training phase, resulting in poor performance of the machine.\
                    \ This problem has been tried to eliminate in this work by finding\
                    \ the differences between the means of a specific feature vector\
                    \ and the means of all features given as inputs to the machine.\
                    \ By performing this process, the reconstruction of the actual\
                    \ features is increased which ultimately reduces the error generated\
                    \ during the training phase of the model. The developed model\
                    \ has been applied to three different datasets of pneumonia diseases\
                    \ and the results have been compared with other state of the art\
                    \ techniques using different performance evaluation parameters.\
                    \ The proposed model gave highest accuracy of 98.56% followed\
                    \ by standard RBM, SVM, KNN, and decision tree which gave accuracies\
                    \ of 97.53%, 92.62%, 91.64%, and 88.77%, respectively, for dataset\
                    \ named dataset 2. Similarly, for the dataset 1, the highest accuracy\
                    \ of 96.66 has been observed for the eRBM followed by srRBM, KNN,\
                    \ decision tree, and SVM which gave accuracies of 90.22%, 89.34%,\
                    \ 87.65%, and 86.55%, respectively. In the same way, the accuracies\
                    \ observed for the dataset 3 by eRBM, standard RBM, KNN, decision\
                    \ tree, and SVM are 92.45%, 90.98%, 87.54%, 85.49%, and 84.54%,\
                    \ respectively. Similar observations can also be seen for other\
                    \ performance parameters showing the efficiency of the proposed\
                    \ model. As revealed in the results obtained, a significant improvement\
                    \ has been observed in the working of the RBM by introducing a\
                    \ new method of weight initialization during the training phase.\
                    \ The results show that the improved model outperforms other models\
                    \ in terms of different performance evaluation parameters, namely,\
                    \ accuracy, sensitivity, specificity, F1-score, and ROC curve.\n\
                    \n1. Introduction\nPneumonia is a provocative surrounding of the\
                    \ lung fundamentally impacting the little air sacs known as alveoli.\
                    \ Results routinely join a blend of the valuable or dry hack,\
                    \ chest torture, fever, and inconvenience unwinding. Pneumonia\
                    \ is for the most part achieved by tainting with contaminations\
                    \ or organisms and less as a rule by various microorganisms. Recognizing\
                    \ reliable microorganisms can be problematic. The investigation\
                    \ is regularly established on signs and actual assessment. We\
                    \ can diagnose pneumonia through chest x-ray, blood tests, and\
                    \ culture of the sputum, and through it, the symptoms of pneumonia\
                    \ are observed [1]. The affliction may be requested by where it\
                    \ was picked up, for instance, crisis center got or clinical administrations-related\
                    \ pneumonia. Persons with compelling pneumonia routinely have\
                    \ a beneficial hack, fever, chills, breath problem, and infection\
                    \ in the chest [2].\n\nIn the people, chaos may be the most obvious\
                    \ sign. Chaos may be the most obvious sign in the people. The\
                    \ regular signs in youths are fever, hack, and problematic relaxing\
                    \ [3]. Fever is not exactly the symptom of it but various other\
                    \ standard disorders might be absent in ailment wretchedness or\
                    \ the old. Moreover, a hack is frequently absent in children under\
                    \ 2 months old. More genuine signs and signs in children may join\
                    \ blue-contacted skin, hesitance to drink, seizures, advancing\
                    \ heaving, limits of temperature, or a decreased level of mindfulness\
                    \ [4].\n\nSubsequently, a chest yield, for instance, x-bars and\
                    \ computer tomography (CT) checks are embraced to all individuals\
                    \ with potential pneumonia results for speedier examination and\
                    \ separation of the corrupted individuals [5].\n\nA patient experiencing\
                    \ pneumonia has fast breathing, fever, dry hack, hypertension,\
                    \ and a high heartbeat rate. In the manual test, specialists would\
                    \ check fast breathing, pulse, and high heartbeat rate which could\
                    \ likewise be side effects of weakness, circulatory strain, or\
                    \ essentially hyperpressure. So, there are chances that the specialist\
                    \ is mixing up exhaustion, high BP, and hyperpressure for pneumonia.\
                    \ This cycle of the manual test is right off the bat tedious.\
                    \ Furthermore, it would be deluding such that specialists would\
                    \ botch the genuine minor illness or disease for something genuine\
                    \ as pneumonia. Thirdly, in the manual test, the specialist can\
                    \ commit an error in record keeping or he can miss any minor detail.\
                    \ In the manual test, more staff necessity would cost a ton. The\
                    \ patient\u2019s clinical history would not be known to the specialist.\
                    \ Moreover, the human blunder is consistently impending which\
                    \ would cause the issue. So, as opposed to treating the minor\
                    \ illness, treatment of pneumonia would begin and it would have\
                    \ some results, i.e., some unfavourably susceptible responses\
                    \ and unsettling influence in ordinary metabolic cycles[7].\n\n\
                    The machine learning algorithm and calculation are basic to create\
                    \ sagacious decisions that will help trained professionals and\
                    \ radiologists to get more information to shield themselves from\
                    \ misdiagnosing a patient. This work looks at open entryways for\
                    \ applying machine learning answers for acknowledgment of pneumonia\
                    \ on chest x-shaft images.\n\nThe technique is coordinated in\
                    \ three stages. In the essential stage, the principle five x-pillar\
                    \ pictures that are by and large like the patient\u2019s x-bar\
                    \ are recuperated from a lot of reference x-bar pictures using\
                    \ content-based picture recuperation (CBIR) strategy. The CBIR\
                    \ procedure uses midway radon change and Bhattacharya shape likeness\
                    \ measure to manage negligible relative mutilation and, moreover,\
                    \ to enlist the degree of comparability among data and reference\
                    \ CXR pictures independently.\n\nIn machine learning techniques,\
                    \ methods such as automatic disease detection, artificial neural\
                    \ method, and logistic regression methods are used for the detection\
                    \ of disease. Programmed identification of pneumonia uses the\
                    \ verifiable component of the lung\u2019s airspace [8]. The strategy\
                    \ relies upon the examination of no inflexible deformable selection\
                    \ driven subsequently isolated lungs areas and lungs divided ROI\
                    \ restricted component extraction. Tests performed on 412 chest\
                    \ x-shaft pictures containing 206 standard and 206 pneumonic cases\
                    \ from the chest X-ray 14 dataset suggest that the introduction\
                    \ of the proposed method for the modified revelation of pneumonia\
                    \ using separated lungs is on a very basic level in a manner that\
                    \ is superior to ordinary procedure using full chest x-pillar\
                    \ pictures [9]. The ordinary precision of the method is 3.54%\
                    \ higher than the regular technique. The logistic regression classifier\
                    \ with infection disclosure precision of 95.63% outmaneuvers the\
                    \ other benchmarked classifiers using partitioned lungs locale.\
                    \ Regardless, despite high precision, the system needs more reliable\
                    \ component examination strategies and exhaustive testing on a\
                    \ tremendous number of continuous analyses.\n\nMachine learning\
                    \ techniques were not too powerful. These techniques too provided\
                    \ ambiguous results, and to overcome its inefficiency, techniques\
                    \ of deep learning were used. Chest x-beam 23 radiography (CXR)\
                    \ is a quick, viable, and low estimated investigation that distinguishes\
                    \ the attainable COVID-19-related pneumonia. This notice researches\
                    \ the achievability of utilizing a profound becoming acquainted\
                    \ with a 25 based choice tree classifier for identifying COVID-19\
                    \ from CXR pics. The proposed classifier 26 contains three parallel\
                    \ choice trees, each informed by a profound picking up information\
                    \ on model with convolution 27 neural network dependent on the\
                    \ PyTorch outline. The primary choice tree orders the chest X-ray\
                    \ photos 28 as consistently or uncommon. The 2d tree distinguishes\
                    \ the peculiar depictions that fuse side effects of 29 tuberculosis,\
                    \ though the third does likewise for COVID-19. The exactness of\
                    \ the essential and 30 subsequent option lumber are 98% and 80%,\
                    \ individually, though the basic precision of the 31 third decision\
                    \ tree is 95 [10, 11].\n\nIn this paper, an enhanced model of\
                    \ restricted Boltzmann machine (named eRBM) is used for detection\
                    \ of pneumonia in x-ray images. The enhancement in the operational\
                    \ procedure of standard RBM has been introduced to eliminate a\
                    \ major drawback of random weight initialization which leads to\
                    \ improper feature learning of the model during the training phase\
                    \ resulting in poor performance of the machine. This modification\
                    \ has introduced significant improvement in the working mechanism\
                    \ of RBM which has increased its power for pneumonia detection\
                    \ process. The rest of paper is organized as follows: Section\
                    \ 2 represents the related, Section 3 shows the motivation behind\
                    \ the work, Section 4 shows the working mechanism of standard\
                    \ RBM, and Section 5 consists of the proposed methodology. Experimental\
                    \ setup and results and discussion have been presented in Section\
                    \ 6 and Section 7, respectively, whereas Section 8 shows the conclusion.\n\
                    \n2. Related Work\nDifferent critics analysed data of pneumonia\
                    \ detection in the researches to find the accuracy, precision,\
                    \ and sensitivity as they used machine learning and deep learning\
                    \ techniques to find out the exact results and accuracy. Comparison\
                    \ with previous researches has also been made by critics. The\
                    \ deep learning technique is more effective for pneumonia detection.\
                    \ Artificial Intelligence technique was also used for pneumonia\
                    \ detection. To find out the accuracy, precision, and sensitivity,\
                    \ characterization of COVID-19, non-COVID-19 viral pneumonia,\
                    \ and bacterial pneumonia were performed based on typical chest\
                    \ x-beams images obtained from online dataset. The dataset incorporates\
                    \ three envelopes (training, approval, and testing with a total\
                    \ scope of 5856 quite horrible cases). The models have been gifted\
                    \ the utilization of 423 COVID-19, 1458 viral pneumonia, and 1579\
                    \ customary chest x-beam pictures on 2 establishments: (1) growth\
                    \ and (2) without expansion. The designs achieved better correctness,\
                    \ sensitivities, and specificities. Coronavirus, non-COVID-19\
                    \ viral pneumonia, and bacterial pneumonia were correctly classified\
                    \ with 93% accuracy in our proposed model [12, 13].\n\nLogistic\
                    \ regression is used for pneumonia detection. Logistic regression\
                    \ can be used to analyze pneumonia detection. We utilize a logistic\
                    \ regression model to arrange whether or no longer has a given\
                    \ x-beam conveyed pneumonia [14]. Strategic relapse works pleasantly\
                    \ as a gauge because of the reality that it is far beautiful smooth\
                    \ to actualize. For this mission, we mindfulness of the paired\
                    \ kind, attempting to group a particular X-ray as having pneumonia\
                    \ or no more. Pictures from the NIH dataset are 1024\u2009\xD7\
                    \u20091024. Strategic regression genuinely transforms into more\
                    \ prominent memory, serious than deep learning. We utilize a calculated\
                    \ relapse model to the group whether a given x-beam conveys pneumonia.\
                    \ Strategic relapse works pleasantly as a pattern because of the\
                    \ reality it miles quite smooth to place in power. Calculated\
                    \ relapse accomplishes an accuracy rating of 0.60 on the investigate\
                    \ set, utilizing 32\u2009\xD7\u200932 photographs. Dataset is\
                    \ made solely out of x-ray depictions that are focused inside\
                    \ the zone of view [15].\n\nSupport vector machine is used for\
                    \ pneumonia detection. To find out the accuracy, precision, and\
                    \ sensitivity, CT photos of a total of 2685 members have been\
                    \ reflectively gathered. In this dataset, multiple times have\
                    \ been the affirmed COVID-19. CT convention comprises of a hundred\
                    \ and twenty kV reproduced chest thickness that goes from 0.625\
                    \ to 2\u2009mm, with breath safeguard at the full idea. For the\
                    \ proposed approach, we run the model 100 times and found that\
                    \ the most profundity of them was the iteration number 10. The\
                    \ proposed method, named tainting length-mindful irregular woods,\
                    \ incorporates a three-degree decision tree to cut subjects into\
                    \ explicit organizations dependent on the size of aroused sores\
                    \ and dictated via arbitrary timberlands for order in every enterprise.\
                    \ The normal exhibition of the proposed approach was assessed\
                    \ through a 5-crease go-approval. Correlation methodologies comprise\
                    \ strategic relapse (LR), help vector machine (SVM), and neural\
                    \ network (NN). The LR and NN procedures perform further, and\
                    \ SVM has especially lower execution. Results are promising, demonstrating\
                    \ 97% affectability, 83.3% particularity, and 87.9% exactness\
                    \ [16].\n\nStacked autoencoder technique is used for pneumonia\
                    \ detection. To find out the accuracy, precision, and sensitivity,\
                    \ a stacked autoencoder locator adaptation is proposed to upgrade\
                    \ the general exhibition of the recognition models comprising\
                    \ of accuracy cost and remember rate. Our model is electronic\
                    \ with a structure without the need for manage work extraction.\
                    \ The stacked autoencoder locator model can help the forefront\
                    \ clinicians to analyze suspected occasions. Our model accomplishes\
                    \ the normal exactness, accuracy, review, and F1-score pace of\
                    \ 94.7%, 96.54%, 94.1%, and 94.8%, separately [17]. Long short\
                    \ term memory is used for pneumonia detection. To find out the\
                    \ accuracy, precision, and sensitivity, LSTM has the capacity\
                    \ of an RNN in demonstrating time assortment. Time dispersion\
                    \ is utilized with LSTM and the main CNN layer to exchange the\
                    \ images into time arrangement records that are proper for the\
                    \ LSTM shape, and that is seen by utilizing 4 CNN blocks, every\
                    \ one of which fundamentally has a convolutional layer and a bunch\
                    \ standardization layer, and a couple of squares likewise have\
                    \ pooling and dropout layers. This part is for trademark extraction.\
                    \ The characterization component incorporates a straightened layer,\
                    \ two squares of thick dropout layers, and a thick yield layer\
                    \ with a sigmoid initiation trademark that arranges the yield\
                    \ photograph to pneumonia. A freely accessible pneumonia detection\
                    \ dataset of chest x-beams in Kaggle transformed into utilized,\
                    \ which incorporates a total of 5856 pictures caught by methods\
                    \ for an advanced processed radiography (CR) framework. Around\
                    \ 1584 of them are ordinary, and 4273 recommend pneumonia (65%\
                    \ for bacterial pneumonia and 35% for viral pneumonia). A profound\
                    \ learning system for pneumonia characterization with four particular\
                    \ CNN designs was proposed. Two of them were pretalented models,\
                    \ Resnet152v2 and Mobilenetv2, and the others have been planned\
                    \ without any preparation. We assessed the proposed models by\
                    \ contrasting them and later similar examinations. The test execution\
                    \ of our proposed profound Learning System becomes evaluated dependent\
                    \ on exactness, accuracy, F1-rating, remembering, and AUC, and\
                    \ our model affirmed estimations of 99.22%, 99. 43%, 99.44%, 99.44%,\
                    \ and 99.77%, separately. Our proposed Resnet152v2 model finished\
                    \ the best results in examination with the others [18].\n\nNeural\
                    \ network was likewise utilized for pneumonia recognition. To\
                    \ discover the exactness, accuracy, and affectability, dataset\
                    \ holds two kinds of chest x-pillar images: normal and pneumonia,\
                    \ which are taken care of in Two Coordinators. In the pneumonia\
                    \ envelope, two kinds of express pneumonia can be seen by the\
                    \ report name: bacteria and virus [19]. Outcomes of seven unequivocal\
                    \ AI estimations: accuracy, AUC, affectability, disposition, and\
                    \ kappa were used to overview the introduction of those seven\
                    \ strategies. RF is the most imperative accuracy \u2217rate (0.917),\
                    \ followed by C5.0 (0.912), SVM (0.871), and CART (0.804) [20].\
                    \ Machine learning techniques were also used for pneumonia clues.\
                    \ To find out the accuracy, precision, and sensitivity, the proposed\
                    \ CAD structure, COVID-19, could decide COVID-pneumonia cases\
                    \ to have an accuracy of 0.965 (sensitivity\u2009=\u200993.54%;\
                    \ specificity\u2009=\u200990.32%; and accuracy\u2009=\u200991.94%)\
                    \ [21, 22]. CNN and MLP were also used for pneumonia detection.\
                    \ To find out the accuracy, precision, and sensitivity, two learning\
                    \ models, neural associations known as CNN and MLP, are depicted,\
                    \ portrayed in the sections underneath. It is possible to see\
                    \ the structure of both neural associations. The course of action\
                    \ of pictures contains 5863 x-pillar pictures and two classes\
                    \ (pneumonia and normal). Chest x-shaft pictures were browsed\
                    \ pediatric patients developed one to five years. For the performance\
                    \ evaulation of the proposed mode, the metrics used to assess\
                    \ the outcomes are precision, recall, TP, TN, and F1 score. The\
                    \ proposed category fashions prove to be the category, with CNN\
                    \ obtaining 94.4% accuracy and MLP with 92.6% [23].\n\n3. Motivation\n\
                    Machine learning and deep learning techniques are applied for\
                    \ pneumonia detection, but still, the need for improvement is\
                    \ required. A restricted Boltzmann machine will be formulized\
                    \ for better accuracy. This model will achieve comparatively better\
                    \ accuracy than other models. An organized deep learning model\
                    \ that will be developed is automatic pneumonia detection. The\
                    \ efficient model would be generated and it will have an advantage\
                    \ in ANN and Deep Learning techniques because a new model is being\
                    \ proposed in this field [24]. Various techniques of Machine Learning\
                    \ are being applied for pneumonia detection to find out the accuracy,\
                    \ precision, and sensitivity. The accuracy of the Logistic Regression\
                    \ technique is 0.60%, Support vector Machine is 87.9%, and K-nearest\
                    \ neighbor technique is 67.5%. The accuracy of these all machine\
                    \ learning techniques is very low and it will affect the whole\
                    \ result. Even a single technique accuracy is not authentic and\
                    \ valid to achieve powerful, reasonable, and acceptable accuracy.\
                    \ Various techniques of Deep Learning are also applied for pneumonia\
                    \ detection to find out the accuracy. The accuracy of the conventional\
                    \ neural network is 92% and MLP is 92.1% and the deep learning\
                    \ algorithm is 73%. The accuracy of these deep learning techniques\
                    \ is very low; it will affect the whole result. These techniques\u2019\
                    \ results are too not sufficiently reliable to achieve reasonable\
                    \ and acceptable accuracy. In the deep learning technique usually\
                    \ a complex structure is used for pneumonia detection. So, due\
                    \ to the use of complex structure, complexity is increased and\
                    \ there will be overfitting. The training accuracy in overfitting\
                    \ is better but the accuracy of testing is not better because\
                    \ this is only used for memorization and does not understand size\
                    \ patterns. While on the other hand, if we use a simple structure,\
                    \ there will be underfitting [25]. In the case of underfitting,\
                    \ the accuracy for both training and testing datasets is not in\
                    \ an acceptable range. The training and testing in underfitting\
                    \ are not appropriate because underfitting does not recognize\
                    \ the overall pattern. So, we will overcome that problem. We want\
                    \ to create a system that would be neither simple nor complicated.\
                    \ A trial and error mechanism system would be found out which\
                    \ would be without the above problems. Most authors have examined\
                    \ normal and abnormal pneumonia whether it exists or not but could\
                    \ not distinguish between bacterial and viral pneumonia. We will\
                    \ distinguish between bacterial and viral pneumonia [24].\n\n\
                    4. Restricted Boltzmann Machine for Disease Detection in X-Ray\
                    \ Images\nA restricted Boltzmann machine is used for disease detection.\
                    \ It has been used for the detection of several diseases. For\
                    \ example, applied RBM for detection of predicting drug target;\
                    \ RBM model to reasonably encode various wellsprings of information\
                    \ about DTIs and accurately predict different sorts of DTIs, for\
                    \ instance, drug-target associations or prescription strategies\
                    \ for movement.\n\nTests on two public databases showed that our\
                    \ count can achieve astounding gauge execution with high AUPR\
                    \ scores. Further tests indicated that our procedure can infer\
                    \ a once-over of novel DTIs, which is useful for drug repositioning.\
                    \ Disregarding the way that our figuring has been attempted particularly\
                    \ on quick and abnormal medicine target associations, and three\
                    \ prescription strategies for movement, it is general and can\
                    \ be easily loosened up to organize various kinds of DTIs (for\
                    \ instance, phenotypic effects). Tests on two public databases\
                    \ show that our kept Boltzmann machine model can satisfactorily\
                    \ get the inert features of a DTI put together and achieve brilliant\
                    \ execution on predicting different sorts of DTIs, with the area\
                    \ under precision survey twist up to 89.6. These results show\
                    \ that our system can have significantly sensible relevance to\
                    \ DTI Figures 1 and 2 and prescription repositioning and hence\
                    \ advance the drug exposure measure [26].\n\nDetails are in the\
                    \ caption following the image\nFigure 1\nOpen in figure viewer\n\
                    PowerPoint\nComparison between normal and viral and bacterial\
                    \ pneumonia alveoli after x-ray detection [6].\nDetails are in\
                    \ the caption following the image\nFigure 2\nOpen in figure viewer\n\
                    PowerPoint\nChest x-ray images used for disease detection.\nApplied\
                    \ RBM for detection of breast cancer classification, we have built\
                    \ a deep neural network (DNN) model using a limited Boltzmann\
                    \ machine with \u201Cscaled form angle\u201D back propagation\
                    \ to order a bunch of histopathological bosom disease pictures\
                    \ [27]. His calculation does not matter any preprocessing ventures\
                    \ before highlight extraction. Calculation 1 straightforwardly\
                    \ removes Tamura highlights from each picture, and the highlights\
                    \ are taken care of to the proposed model of the limited Boltzmann\
                    \ machine (RBM) for picture order. In the prepreparing steps,\
                    \ this calculation improves the differentiation of each picture\
                    \ in the dataset utilizing the proposed contrast-upgrade calculation\
                    \ and afterward extricates the highlights. After that, all the\
                    \ highlights are taken care of to the proposed model of the restricted\
                    \ Boltzmann machine (RBM) for picture arrangement [28]. As a profound\
                    \ learning device, we have executed an unaided limited Boltzmann\
                    \ machine that contains four layers and is guided by a managed\
                    \ back proliferation strategy. For the back-spread, scaled form\
                    \ angle methods have been used.\n\nWe have played out our examinations\
                    \ on the Break His dataset and got 88.7%, 85.3%, 88.6%, and 88.4%\
                    \ precision for the dataset of 40X, 100X, 200X, and 400X amplification\
                    \ factors, individually. The vast majority of the investigations\
                    \ on the Break His dataset decided for the exhibition based on\
                    \ exactness; in any case, in this section, we have additionally\
                    \ considered TPR and FPR esteems alongside a point by point depiction\
                    \ of the ROC bends [29].\n\u2009\nInput:RBM\u2009(v1, \u2026.,\
                    \ vm, h1, \u2026., hn), \u2009training\u2009batch\u2009S,\n\n\u2009\
                    \nOutput:mathematical equation\n\n(1)\nmathematical equation\n\
                    \n(2)\nfor\u2009all\u2009the\u2009v\u2009 \u2208 \u2009s\u2009\
                    do\n\n(3)\nv(0) \u2190 \u2009v\n\n(4)\n\u2009for\u2009t\u2009\
                    \ = \u20090, \u2026\u2026., k\u2009 \u2212 \u20091\u2009do\n\n\
                    (5)\n\u2003mathematical equation\n\n(6)\n\u2003mathematical equation\n\
                    \n(7)\nfor\u2009i\u2009 = \u20091, \u2026\u2026., n, \u2009j\u2009\
                    \ = 1, \u2026\u2026, m\u2009do\n\n(8)\n\u2003mathematical equation\n\
                    \n(9)\n\u2003mathematical equation\n\n(10)\n\u2003mathematical\
                    \ equation\n\nApplied RBM for detection of brain disorder detection:\
                    \ in-depth learning approaches can naturally extricate information\
                    \ attributes to take care of the issue of removing qualities through\
                    \ their various levelled structures. In this paper, an improved\
                    \ deep belief network (DBN)-based picture grouping model has been\
                    \ proposed by consolidating the Discrete Wavelet Change (DWT)\
                    \ for highlight extraction and principal component analysis (PCA)\
                    \ to get a diminished size of separated highlights. Here, the\
                    \ DBN is made out of stacked restricted Boltzmann machines (RBMs)\
                    \ to mine the huger highlights from the decreased datasets layer\
                    \ by layer. For the most part, DBN requires immense and various\
                    \ shrouded layers with an enormous number of concealed units to\
                    \ take in the best highlights from the crude pixels of picture\
                    \ information. This builds the intricacy just as preparing time\
                    \ for the model. Thus, by combining DBN with DWT, both time efficiency\
                    \ has been improved. But, utilizing crude pictures, the separated\
                    \ low-goal picture from DWT is utilized for preparing DBN [30].\n\
                    \nApplied RBM for detection of hypertension retinopathy: hypertensive\
                    \ retinopathy (HR) in the layer of the eye is aggravation brought\
                    \ about by hypertension illness, where there is a basic change\
                    \ of blood vessel in the veins of the retina. Most cardiovascular\
                    \ failures happen in patients brought about by hypertension manifestations\
                    \ of undiscovered. The symptoms of hypertensive retinopathy, for\
                    \ example, are arteriolar narrowing, retinal discharge, and cotton\
                    \ fleece spots. Given these reasons, the early analysis of the\
                    \ manifestations of hypertensive retinopathy is extremely dire\
                    \ to point the counteraction and treatment more exactly. This\
                    \ exploration means building up a framework for early recognition\
                    \ of hypertension retinopathy stage. The proposed technique is\
                    \ to decide the consolidated highlights corridor and vein width\
                    \ proportion (AVR) just as change position with Optic Disk (OD)\
                    \ in retinal pictures to inspect the characterization of hypertensive\
                    \ retinopathy utilizing Deep Neural Networks (DNN) and Boltzmann\
                    \ machines approach. It expected outcomes from this examination\
                    \ which planned a model framework early identification of hypertensive\
                    \ retinopathy stage and broke down the adequacy and precision\
                    \ of the suggested techniques [31].\n\nApplied RBM for detection\
                    \ of blood transfusion prediction: the accessibility of blood\
                    \ bonding has been a repetitive worry for clinical organizations\
                    \ and patients. Effective administration of this asset speaks\
                    \ to a significant test for some medical clinics. Similarly, fast\
                    \ response during bonding choices and arranging is a basic factor\
                    \ to expand understanding consideration. This paper proposes a\
                    \ novel system for anticipating the blood bonding need, in light\
                    \ of accessible data, by methods for restricted Boltzmann machines\
                    \ (RBM). By removing and investigating significant level highlights\
                    \ from 4831 patient records, RBM can manage complex examples acknowledgment,\
                    \ helping directed classifiers in the errand of programmed recognizable\
                    \ proof of blood bonding necessities. Results show that an effective\
                    \ characterization is acquired (96.85%), in light of accessible\
                    \ data from the patient records [32].\n\n5. Proposed Methodology\n\
                    The proposed methodology consists of four steps, (i) read images,\
                    \ (ii) image preprocessing, (iii) classification (differentiated\
                    \ viral-induced pneumonia, bacterial-induced pneumonia, and normal\
                    \ lungs), and (vi) performance evaluation.\n\nThe four steps are\
                    \ followed in this section. The proposed methodology is shown\
                    \ in Figure 3.\n\nDetails are in the caption following the image\n\
                    Figure 3\nOpen in figure viewer\nPowerPoint\nA systematic block\
                    \ diagram has been drawn in which the RBM method is used after\
                    \ taking x-ray images for pneumonia detection.\n5.1. Image Acquisition\n\
                    In this stage, the images of normal and abnormal lungs have been\
                    \ retrieved from the database for possible procedural operations.\
                    \ The data are then profitably split into the Train, Test, and\
                    \ Val: Train contains the readiness data/pictures for demonstrating\
                    \ our model. Val contains pictures that we will use to support\
                    \ our model. Test contains the data that we use to test the model\
                    \ at whatever point it has taken in the associations between the\
                    \ photos and their name (Pneumonia/not Pneumonia). The train dataset\
                    \ is the portion of the dataset that has been used for training\
                    \ our proposed model. A total of 1500 lung images have been considered\
                    \ for experimentation. Out of these 1500 images, 500 images are\
                    \ normal and 1000 images are abnormal having pneumonia. Out of\
                    \ the 1000 abnormal images, 500 are bacterial pneumonia, whereas\
                    \ 500 are viral pneumonia.\n\n5.2. Image Preprocessing\nThe image\
                    \ preprocessing is completed in three stages: Step 1: all the\
                    \ images, initially procured, were first looked at to locate the\
                    \ base tallness and width present in the dataset pictures. After\
                    \ discovering this base measurement, all the dataset pictures\
                    \ were resized to this measurement. Step 2: prehandling of resized\
                    \ pictures is finished by the Image-Net information base. Image-Net\
                    \ information base is an openly accessible PC vision dataset containing\
                    \ a great many pictures with more than a thousand picture classes.\
                    \ Step 3: preprocessing is the way toward improving or upgrading\
                    \ the nature of the information picture and making the element\
                    \ extraction stage more dependable; principle thought process\
                    \ of preprocessing stages is to eliminate clamor present in info\
                    \ picture. In the preprocessing stage middle channel is utilized\
                    \ to eliminate commotion from the info picture and for picture\
                    \ upgrade, power-law changes have been utilized.\n\n5.3. Classification\n\
                    The classifier is a numerical capacity that is executed utilizing\
                    \ characterization calculation which guides input information\
                    \ to a specific classification. A limited Boltzmann machine is\
                    \ a stochastic neural organization comprised of two layers: one\
                    \ of obvious and one of the shrouded units. There are various\
                    \ arrangements of the preparation network that we did not test\
                    \ and could improve the grouping score. To start with, we have\
                    \ just utilized contrastive disparity in one stage; however, this\
                    \ could be changed to a self-assertive number. Second, various\
                    \ calculations could be tried to prepare the confined Boltzmann\
                    \ machine, one of them being tireless contrastive dissimilarity.\
                    \ We additionally accept that utilizing more layers of limited\
                    \ Boltzmann machine could likewise improve recognition. Notwithstanding,\
                    \ this strategy may accompany the expense of more memory use and\
                    \ an expanded testing time. A standard RBM is a generative model\
                    \ with two densely connected layers, one visible layer to represent\
                    \ data and the second is a latent layer to extract stochastic\
                    \ binary features from data. Hidden units are connected to visible\
                    \ nodes using symmetrically weighted connections to model their\
                    \ joint distribution. The bacterial disease is profoundly likely\
                    \ in instances of youth local area obtained pneumonia with alveolar\
                    \ invades on the chest radiograph. Interstitial invades are seen\
                    \ in both viral and bacterial pneumonia. Except for serum CRP\
                    \ levels, routine hematological tests have next to no functional\
                    \ incentive notwithstanding a chest radiograph. All kids with\
                    \ radiologically affirmed pneumonia ought to be treated with antitoxins\
                    \ because, in medical practice, it is difficult to identify only\
                    \ between viral pneumonia and bacterial pneumonia.\n\nRBM is a\
                    \ Stochastic Neural Network which means that each neuron has some\
                    \ disorder behaviour when it is activated. There are two other\
                    \ layers of bias unit's hidden prejudice and visible prejudice\
                    \ in RBM. Input/visible layers consist of different chest x-ray\
                    \ images of pneumonia the hidden layer consists of four classifiers\
                    \ like normal, abnormal bacterial, and viral as shown in Figure\
                    \ 4. The hidden prejudice RBM produces the activation on the forward\
                    \ pass and the visible bias helps RBM to reconstruct the input\
                    \ during a backward pass. The reconstructed input is always different\
                    \ from the actual input because there are no connections among\
                    \ the visible units therefore there is no way of transferring\
                    \ information between them. We are reconstructing the input layer\
                    \ through the activated hidden state instead of calculating the\
                    \ output layer. This process is called be Feed Backward Pass.\
                    \ Backtracking the input layer is activated through hidden neurons.\
                    \ After performing this, an input is reconstructed through the\
                    \ activated hidden state as shown in Figure 5. Let us consider\
                    \ an example in which we have some assumptions that V1 visible\
                    \ unit activates the h1 and h2 hidden unit and the V2 visible\
                    \ unit activates the h2 and h3 hidden. Now when any new visible\
                    \ unit lets V4 come into the machine and it also activates the\
                    \ h1 and h2 units. So, we can back discover the hidden unit easily\
                    \ and also can identify that the characteristics of the new V4\
                    \ neuron are matching with the V1. This is because the V1 is also\
                    \ activated in the same hidden unit earlier.\nmathematical equation\n\
                    (1)\nDetails are in the caption following the image\nFigure 4\n\
                    Open in figure viewer\nPowerPoint\nPneumonia detection is in chest\
                    \ X-ray images using RBM.\nDetails are in the caption following\
                    \ the image\nFigure 5\nOpen in figure viewer\nPowerPoint\nThe\
                    \ graph of an RBM with hidden and visible variables.\nThe value\
                    \ of the joint probability model for the event of paired vector\
                    \ (v, h):\nmathematical equation\n(2)\nwhere Z is given by summing\
                    \ overall possible pairs of the visible and hidden layers.\nmathematical\
                    \ equation\n(3)\nwhere Z is also called a partition function.\n\
                    mathematical equation\n(4)\nThe method which has been proposed\
                    \ in this paper is the conversion of initial weights Wij which\
                    \ are defined indiscriminately. In this method, the worth of Wij\
                    \ is replaced according to the difference between the mean values\
                    \ of all features of the set of training vectors mathematical\
                    \ equation, and the mean of all the values of the features of\
                    \ the training vectors mathematical equation. In other words,\
                    \ if the substance mathematical equation is more than mathematical\
                    \ equation weight obtaining Wij is required. This paper shows\
                    \ that this work exceeds the coincidence of producing a training\
                    \ set of vectors vv\u2009\u2208\u2009s S by the restricted Boltzmann\
                    \ machine. The main thing in this procedure is the initial weight\
                    \ being confined indiscriminately. Thus, the use of a disorderly\
                    \ starting point in this procedure is observed. According to this\
                    \ approach, the conversion of Wij is based on the comparison of\
                    \ mathematical equation \u060C, where 1\u2009\u2264\u2009i\u2009\
                    \u2264\u2009N. Parameter L is the number of training vectors.\
                    \ According to the model in this procedure, we have solved on\
                    \ one hand to put the quantity of energy model for all visible\
                    \ and hidden node arrangement \u2211v,he\u2212E(v, h) in a continuous\
                    \ manner and while on the other hand to decrease the quantity\
                    \ of energy for all feasible values in the hidden layer and the\
                    \ training vector v, \u2211he\u2212E(v, h)[33].\nmathematical\
                    \ equation\n(5)\nBased on the results, we can easily deduce equations.\n\
                    mathematical equation\n(6)\nIn the second intermission of the\
                    \ right side of the equation, the value e\u2212E(v, h) is counted\
                    \ for all arrangements of the hidden and visible layer. We can\
                    \ draw a result from the equation that the deduction of energy\
                    \ between all nodes of the hidden layer and visible training vectors\
                    \ results in the process of the similarity between feasible model\
                    \ and the parameter in the training vectors set v\u2009\u2208\u2009\
                    S. In the proposed procedure, the preliminary weights are replaced\
                    \ to proceed the coincidence of restoration of a set of training\
                    \ vectors by model. However, prejudice values of hidden and viable\
                    \ layers remain unchanged. To replace the weight Wij between all\
                    \ nodes of the hidden layer and all nodes of the visible layer\
                    \ in the \u03B8\u2032 restricted Boltzmann machine model is defined\
                    \ as follows:\nmathematical equation\n(7)\nwhere Wij means the\
                    \ weight replacement should be on the side that exceeds the chance\
                    \ of regenerating the training samples in the feasible restricted\
                    \ Boltzmann model. The replacement of weight is done in a manner\
                    \ that on one side, it could keep consistent the amount of energy\
                    \ of the model for all visible and concealed layers manner, and\
                    \ on the other side, it could deduct the amount of energy for\
                    \ all values in the concealed layer and the training vector. In\
                    \ the following, we try to show in this paper that by replacing\
                    \ the initial values of the weight matrix W to the proposed procedure,\
                    \ the amount \u2211v,he\u2212E(v, h) is not exchanged.\nThe values\
                    \ of bias hidden layer and the bias visible layers are the same\
                    \ in both restricted Boltzmann machines of \u03B8 and \u03B8\u2032\
                    . We can rewrite the elements of sum replaced weight matrix, W,\
                    \ based on the initial weight matrix, W [33].\nmathematical equation\n\
                    (8)\nThen, in consideration of the equations, the following results\
                    \ are obtained:\nmathematical equation\n(9)\n5.4. Performance\
                    \ Evaluation\nExecution of the proposed two-stage pneumonia location\
                    \ framework is assessed factual estimates such as exactness, accuracy,\
                    \ and review [34]. These measures are quickly depicted as follows.\n\
                    \n5.4.1. Confusion Matrix\nA confusion matrix is shaped from the\
                    \ four results; a classifier assumes all information occurrences\
                    \ of a test dataset as positive or negative. This classification\
                    \ or assumption produces four results: positive true, true negative,\
                    \ false positive, and false negative.\n\u2009\nTrue positive:\
                    \ correct positive prediction\n\n\u2009\nFalse positive: incorrect\
                    \ positive prediction\n\n\u2009\nTrue negative: correct negative\
                    \ prediction\n\n\u2009\nFalse negative: incorrect negative prediction\n\
                    \n5.4.2. Accuracy\nIt is a boundary that evaluates the capacity\
                    \ of a technique by estimating a ratio of accurately anticipated\
                    \ cases out of a complete number of cases. Numerically, it is\
                    \ expressed as\nmathematical equation\n(10)\nwhere TP is the number\
                    \ of right forecasts of positive cases by the strategy; TN is\
                    \ the number of right expectations of negative cases by the technique;\
                    \ FP is the number of mistaken expectations of positive cases\
                    \ by the strategy; and TN is the number of incorrect forecasts\
                    \ of negative cases by the technique. In this way, validity is\
                    \ not in every case great to evaluate the display of the model\
                    \ specifically if there should be an occurrence of the asymmetrical\
                    \ dataset. Consequently, there is a need to assess the other execution\
                    \ measurements to test the model.\n5.4.3. Precision\nIt is the\
                    \ proportion of correctly anticipated positive cases to the complete\
                    \ anticipated positive cases. High validity identifies with the\
                    \ low false positive rate. It is expressed as\nmathematical equation\n\
                    (11)\n5.4.4. Recall or Sensitivity\nIt is the proportion of accurately\
                    \ predicted positive inspections to all observations in the actual\
                    \ class.\nmathematical equation\n(12)\n5.4.5. Specificity\nIt\
                    \ is the proportion of accurately predicted negative inspections\
                    \ to all the actual negative observations.\nmathematical equation\n\
                    (13)\n5.4.6. F1-Score\nThe measurements of F1-score in case of\
                    \ uneven class division particularly with a large number of true\
                    \ negative inspections: it supplies a balance between validity\
                    \ and recall [35].\nmathematical equation\n(14)\n6. Experimental\
                    \ Setup\n6.1. Running Environment\nThe whole experimentation was\
                    \ performed on Windows 10 operating system with Python 3.8.6 installed\
                    \ on it. Different types of environments and libraries of Python\
                    \ for deep learning models were used for supporting the experimental\
                    \ setup. The main libraries and tools of Python that supported\
                    \ the experimentation include Numphy, Scipy, Anaconda, TensorFlow,\
                    \ Spyder IDE, and Pycharm. These all were used for different purposes\
                    \ to improve the execution process. The parameters of RBM used\
                    \ are as follows: a restricted Boltzmann machine with binary visible\
                    \ units and binary hidden units. Parameters are estimated using\
                    \ stochastic maximum likelihood (SML), also known as persistent\
                    \ contrastive divergence (PCD) [36]. The number of hidden units\
                    \ has set to its default value that is 256, whereas the learning\
                    \ rate value is 0.1. The batch size has been set to 10, whereas\
                    \ the number of iterations has been varied from 10 to 50 with\
                    \ and increment of 5 to evaluate the performance for different\
                    \ iterations. The verbosity level value has been kept as 0 which\
                    \ shows the silent mode. Further, the biases values of intercept\
                    \ visible and intercept hidden units have been set to the default\
                    \ values of the model.\n\n6.2. Data Specification and Division\n\
                    The proposed model was applied to three different datasets all\
                    \ containing pneumonia with the following details. The data were\
                    \ divided into 70 and 30 ratio for training and testing, respectively,\
                    \ as shown in Table 1.\n(1)\nDataset 1. Total images: 1500, normal\
                    \ images\u2009=\u2009500, and abnormal images\u2009=\u20091000\
                    \ (bacterial pneumonia\u2009=\u2009500; viral pneumonia\u2009\
                    =\u2009500) [37].\n\n(2)\nDataset 2. Total images: 3000, normal\
                    \ images\u2009=\u20091000, COVID-19 images\u2009=\u20091000, and\
                    \ pneumonia images\u2009=\u20091000 [38].\n\n(3)\nDataset 3. Total\u2009\
                    =\u20091248, normal 500, COVID pneumonia 215, and non-COVID pneumonia\
                    \ 533 [39].\n\nTable 1. Description of datasets.\n\u2009\tTotal\
                    \ training samples\tTotal testing samples\tTraining samples\t\
                    Testing samples\nDataset 1\t\u2009\t\u2009\tNormal\tBacterial\t\
                    Viral\tNormal\tBacterial\tViral\n1050\t450\t350\t350\t350\t150\t\
                    150\t150\n\u2009\u2009\nDataset 2\t\u2009\t\u2009\tNormal\tCOVID-19\t\
                    Pneumonia\tNormal\tCOVID-19\tPneumonia\n2100\t900\t700\t700\t\
                    700\t300\t300\t300\n\u2009\u2009\nDataset 3\t\u2009\t\u2009\t\
                    Normal\tCOVID-pneumonia\tNon-COVID-pneumonia\tNormal\tCOVID-pneumonia\t\
                    Non-COVID-pneumonia\n874\t374\t350\t150\t374\t150\t165\t159\n\
                    7. Results and Discussion\nIn order to evaluate the performance\
                    \ of the proposed model adequately, the model was applied to three\
                    \ different datasets, as shown in Table 1. The comparison of the\
                    \ model with other state of the art techniques in terms of classification\
                    \ accuracy, precision, recall, specificity, F1-score, and ROC\
                    \ curve is presented in this section with sufficient detail.\n\
                    \nAs revealed in Table 2, the model shows the accuracy of enhanced\
                    \ RBM 97.90, and in standard, RBM is 94.85 and other techniques\
                    \ have different accuracies. The results show that the accuracy\
                    \ of enhanced RBM is more than standard RBM as well as all other\
                    \ standard models. In this way, if you observe precision, recall/sensitivity,\
                    \ specificity, and F1-score, then it can be concluded that the\
                    \ model shows substantial improvement in enhanced RBM.\n\nTable\
                    \ 2. Dataset 1: training samples.\nModel\tAccuracy\tPrecision\t\
                    Recall\tSpecificity\tF1-score\nKNN\t92.61\t0.9318\t0.9387\t0.9413\t\
                    2.5432\nSVM\t90.71\t0.9171\t0.9224\t0.9173\t2.1879\nDT\t91.54\t\
                    0.9213\t0.9311\t0.9344\t2.4316\nsRBM\t94.85\t0.9732\t0.9849\t\
                    0.9739\t2.9548\neRBM\t97.90\t0.9768\t0.9912\t0.9774\t2.9636\n\
                    Bold values highlight the performance of our model, i.e., Restricted\
                    \ Boltzmann Machine.\nFigure 6 shows the ROC curve of the proposed\
                    \ model (enhanced RBM) in comparison with other classifiers considered.\
                    \ Although there are many fluctuations in the curve, but overall,\
                    \ the true positive rate of eRBM is better than all other models.\n\
                    \nDetails are in the caption following the image\nFigure 6\nOpen\
                    \ in figure viewer\nPowerPoint\nROC curve of the proposed model\
                    \ (enhanced RBM) in comparison with other classifiers considered\
                    \ for training of dataset 1.\nTable 3 shows the comparison of\
                    \ eRBM with sRBM, KNN, SVM, and decision tree in terms of classification\
                    \ accuracy, precision, recall, specificity, and F1-score. For\
                    \ all the performance evaluation parameters, a considerable improvement\
                    \ can be observed in the performance of the proposed model. The\
                    \ result in the improvement is due to the enhancement introduced\
                    \ in the standard operational working mechanism of standard RBM.\
                    \ If keenly observed, the performance of all the models for this\
                    \ testing dataset is slightly worse than that of training dataset.\
                    \ This is due to overfitting problem in which the model usually\
                    \ gives better results on training dataset than the testing dataset.\n\
                    \nTable 3. Dataset 1: testing samples.\nModel\tAccuracy\tPrecision\t\
                    Recall\tSpecificity\tF1-score\nKNN\t89.34\t0.9217\t0.8942\t0.9286\t\
                    2.6973\nSVM\t86.55\t0.8753\t0.8521\t0.8777\t2.2286\nDT\t87.65\t\
                    0.9113\t0.8822\t0.9075\t2.6437\nsRBM\t90.22\t0.9568\t0.9366\t\
                    0.9571\t2.8973\neRBM\t96.66\t0.9863\t0.9797\t0.9859\t2.9391\n\
                    Bold values highlight the performance of our model, i.e., Restricted\
                    \ Boltzmann Machine.\nFigure 7 shows the ROC of the eRBM in comparison\
                    \ with other state of the art classification models. The figure\
                    \ shows that the highest true positive rate has been observed\
                    \ for the eRBM followed by the rate of standard RBM. There are\
                    \ some variations in the true positive rates of all other models\
                    \ considered. If the ROCs of the training and testing datasets\
                    \ are deeply observed, it can be easily concluded that the true\
                    \ positive rate of training dataset is slightly higher than the\
                    \ rate of testing dataset.\n\nDetails are in the caption following\
                    \ the image\nFigure 7\nOpen in figure viewer\nPowerPoint\nROC\
                    \ of the eRBM in comparison with other state of the art classification\
                    \ models for testing of dataset 1.\nThe performance of the proposed\
                    \ model for training dataset of the second dataset is shown in\
                    \ Table 4. The highest classification accuracy, precision, recall,\
                    \ specificity, and F1-score have been observed for the eRBM followed\
                    \ by standard RBM. For all other classification techniques, there\
                    \ are some variations in the results. For example, the classification\
                    \ accuracy of KNN is higher than decision tree but the precision\
                    \ of decision tree is higher than that of KNN. The table shows\
                    \ that the performance of SVM is better than KNN and decision\
                    \ tree but poor than standard RBM and eRBM for all the considered\
                    \ evaluation parameters.\n\nTable 4. Dataset 2: training samples.\n\
                    Model\tAccuracy\tPrecision\tRecall\tSpecificity\tF1-score\nKNN\t\
                    93.71\t0.9389\t0.9523\t0.9562\t2.7667\nSVM\t94.43\t0.9512\t0.9611\t\
                    0.9641\t2.8123\nDT\t93.33\t0.9448\t0.9527\t0.9521\t2.7827\nsRBM\t\
                    96.49\t0.9886\t0.9833\t0.9822\t2.9711\neRBM\t99.30\t0.9971\t0.9989\t\
                    0.9895\t2.9879\nBold values highlight the performance of our model,\
                    \ i.e., Restricted Boltzmann Machine.\nFigure 8 shows the ROC\
                    \ of eRBM in comparison with other approaches considered for training\
                    \ dataset of the second dataset. The highest positive rate has\
                    \ been observed for the eRBM followed by the standard RBM. If\
                    \ this is keenly observed, the true positive rate for all the\
                    \ models is better than that of training samples of dataset 1.\n\
                    \nDetails are in the caption following the image\nFigure 8\nOpen\
                    \ in figure viewer\nPowerPoint\nROC of eRBM in comparison with\
                    \ other approaches considered for training of the dataset 2.\n\
                    Table 5 shows the comparison of the eRBM with other approaches\
                    \ considered to evaluate the performance of the model in terms\
                    \ of accuracy, precision, recall, specificity, and F1-score for\
                    \ testing samples of dataset 2. For all the outlined parameters,\
                    \ the performance of the eRBM is better than all the other models.\
                    \ If this testing dataset performance is compared with the training\
                    \ dataset, it can be concluded that the performance of all models\
                    \ for testing dataset is slightly worse than that of training\
                    \ dataset.\n\nTable 5. Dataset 2: testing samples.\nModel\tAccuracy\t\
                    Precision\tRecall\tSpecificity\tF1-score\nKNN\t91.64\t0.9273\t\
                    0.9266\t0.9468\t2.7391\nSVM\t92.62\t0.9368\t0.9466\t0.9465\t2.7951\n\
                    DT\t88.77\t0.8789\t0.8837\t0.8862\t2.6525\nsRBM\t97.53\t0.9755\t\
                    0.9741\t0.9695\t2.9611\neRBM\t98.56\t0.9897\t0.9878\t0.9886\t\
                    2.9754\nBold values highlight the performance of our model, i.e.,\
                    \ Restricted Boltzmann Machine.\nFigure 9 shows the ROC comparison\
                    \ of the proposed model with other state of the art models. As\
                    \ shown in the figure, the true positive rate of eRBM is higher\
                    \ than all the other models showing the strength of the improvements\
                    \ introduced in the working mechanism of standard RBM. A sufficient\
                    \ amount of difference can be observed in the performance of eRBM\
                    \ as compared to other classifiers. If the ROCs of both training\
                    \ and testing samples of dataset 2 are keenly observed, it can\
                    \ be concluded that true positive rate for all the models of testing\
                    \ samples is slightly lower than training data samples.\n\nDetails\
                    \ are in the caption following the image\nFigure 9\nOpen in figure\
                    \ viewer\nPowerPoint\nROC comparison of the proposed model with\
                    \ other state of the art models for testing of dataset 2.\nTable\
                    \ 6 shows the performance evaluation parameters for training samples\
                    \ of dataset 3 for the eRBM and other classifiers. The highest\
                    \ accuracy has been observed for eRBM followed by sRBM, KNN, decision\
                    \ tree, and SVM, respectively. In the same way, similar observations\
                    \ can be found for other parameters as well. For all parameters,\
                    \ the performance of eRBM is better than all other approaches,\
                    \ whereas for other models, variations can be observed in the\
                    \ results. If the results are deeply observed, it can be concluded\
                    \ that performance of all models for dataset 3 is worse than the\
                    \ other datasets. The reason is the small amount of both training\
                    \ and testing samples as outlined in the dataset specification\
                    \ and descriptions.\n\nTable 6. Dataset 3: training samples.\n\
                    Model\tAccuracy\tPrecision\tRecall\tSpecificity\tF1-score\nKNN\t\
                    89.64\t0.8865\t0.8748\t0.8855\t2.3214\nSVM\t86.32\t0.8545\t0.8534\t\
                    0.8612\t1.8953\nDT\t88.55\t0.8761\t0.8723\t0.8698\t1.8934\nsRBM\t\
                    92.765\t0.9144\t0.9157\t0.9213\t2.7622\neRBM\t94.78\t0.9363\t\
                    0.9376\t0.9411\t2.8691\nFigure 10 shows the ROC of eRBM in comparison\
                    \ with other standard classification models. The figure reveals\
                    \ that the true positive rate of the proposed model is better\
                    \ than all the other models showing the better architecture of\
                    \ the proposed model. If this curve is compared with that of training\
                    \ data samples curves for other two datasets, it can be observed\
                    \ that true positive rate of training samples of dataset 3 is\
                    \ lower than the other datasets due to small data samples.\n\n\
                    Details are in the caption following the image\nFigure 10\nOpen\
                    \ in figure viewer\nPowerPoint\nROC of eRBM in comparison with\
                    \ other standard classification models for training of dataset\
                    \ 3.\nThe performance of eRBM with sRBM, KNN, SVM, and decision\
                    \ tree for testing samples of dataset 3 is shown in Table 7. As\
                    \ shown in the table, the highest accuracy, precision, recall,\
                    \ specificity, and F1-score have been observed for the proposed\
                    \ model followed by the performance of sRBM for all the evaluation\
                    \ parameters. If this performance is compared with training samples\
                    \ of dataset 3, it is clear that the performance for testing samples\
                    \ is slightly poorer than training data samples.\n\nTable 7. Testing\
                    \ samples for dataset 3.\nModel\tAccuracy\tPrecision\tRecall\t\
                    Specificity\tF1-score\nKNN\t87.54\t0.8741\t0.8342\t0.8755\t2.2316\n\
                    SVM\t84.54\t0.8454\t0.8434\t0.8555\t1.8765\nDT\t85.49\t0.8623\t\
                    0.8621\t0.8453\t1.8767\nsRBM\t90.98\t0.9002\t0.9032\t0.9112\t\
                    2.7234\neRBM\t92.45\t0.9113\t0.9211\t0.9237\t2.8678\nBold values\
                    \ highlight the performance of our model, i.e., Restricted Boltzmann\
                    \ Machine.\nThe true positive and false positive rates of all\
                    \ the models are shown in Figure 11. As shown in the figure, the\
                    \ highest true positive rate has been observed for the proposed\
                    \ model followed by the standard RBM, whereas there are different\
                    \ fluctuations in the true positive rates of all other models.\
                    \ If this is compared with other two datasets, it can be concluded\
                    \ that the true positive rate of testing data samples for both\
                    \ of them is higher than this testing sample. The reason behind\
                    \ is the smaller dataset which becomes difficult for the models\
                    \ to get trained adequately.\n\nDetails are in the caption following\
                    \ the image\nFigure 11\nOpen in figure viewer\nPowerPoint\nTrue\
                    \ positive and false positive rates of all the models considered\
                    \ in the research study.\n7.1. Performance Comparison of Different\
                    \ Datasets\nIn this section, the comparison of the enhanced RBM\
                    \ with standard RBM, KNN, decision tree, and SVM has been presented\
                    \ using different performance evaluation parameters. For all the\
                    \ considered three datasets, the accuracy, precision, specificity,\
                    \ recall, and F1-scores have been shown in Figure 11 using different\
                    \ classification models.\n\nThe training and testing accuracies\
                    \ of eRBM, sRBM, decision tree, SVM, and KNN for the three datasets\
                    \ are shown in Figures 12 and 13. In case of training dataset,\
                    \ the proposed model gave highest accuracy of 99.3 for the 2nd\
                    \ dataset followed by the accuracies of 97.9 and 94.78 for dataset\
                    \ 1 and dataset 3, respectively. If keenly observed, all the classifiers\
                    \ gave highest accuracies for the 2nd dataset showing their efficiency\
                    \ in capturing valuable information from the dataset. Similar\
                    \ observations can be found for the testing dataset as well where\
                    \ the eRBM provided 98.56 accuracy for the 2nd dataset followed\
                    \ for 96.66 and 92.45, respectively.\n\nDetails are in the caption\
                    \ following the image\nFigure 12\nOpen in figure viewer\nPowerPoint\n\
                    Training accuracies of eRBM, sRBM, decision tree, SVM, and KNN\
                    \ for the three datasets.\nDetails are in the caption following\
                    \ the image\nFigure 13\nOpen in figure viewer\nPowerPoint\nTesting\
                    \ accuracies of eRBM, sRBM, decision tree, SVM, and KNN for the\
                    \ three datasets.\nFigures 14 and 15 show the training and testing\
                    \ specificity of all classifiers for the three datasets. The highest\
                    \ specificity of 0.9895 has been provided by eRBM for dataset\
                    \ 2 followed by dataset 1 and dataset 3 specificity which gave\
                    \ 0.9774 and 0.9491, respectively, for training data samples.\
                    \ Similarly, for testing dataset, the highest specificity has\
                    \ been observed for all the classifiers using dataset 2 followed\
                    \ by dataset 1 and dataset 3, respectively. All the classifiers\
                    \ except the proposed model have different values of specificity\
                    \ for all the datasets. The lowest specificity has been observed\
                    \ for dataset 3 for all the considered classification techniques\
                    \ which shows that there is some problem in capturing the details\
                    \ leading to less efficiency of the model.\n\nDetails are in the\
                    \ caption following the image\nFigure 14\nOpen in figure viewer\n\
                    PowerPoint\nTraining specificity of all classifiers for the three\
                    \ datasets.\nDetails are in the caption following the image\n\
                    Figure 15\nOpen in figure viewer\nPowerPoint\nTesting specificity\
                    \ of all classifiers for the three datasets.\nThe precision of\
                    \ both training and testing data samples for all the classifiers\
                    \ is shown in Figures 16 and 17. If the figure is keenly observed,\
                    \ the proposed eRBM model gave higher value of precision than\
                    \ all classifiers for three datasets showing the worth of improvement\
                    \ that has been introduced in the working mechanism of the RBM.\n\
                    \nDetails are in the caption following the image\nFigure 16\n\
                    Open in figure viewer\nPowerPoint\nPrecision of training data\
                    \ samples for all the classifiers.\nDetails are in the caption\
                    \ following the image\nFigure 17\nOpen in figure viewer\nPowerPoint\n\
                    Precision of testing data samples for all the classifiers.\nAs\
                    \ shown in Figures 18 and 19, the highest F1-score value is observed\
                    \ for the proposed eRBM in case of both training and testing data\
                    \ samples followed by the sRBM, decision tree, SVM, and KNN, respectively.\
                    \ There can be seen many fluctuations in the performance of other\
                    \ models for both training and testing datasets in terms of F1-score.\n\
                    \nDetails are in the caption following the image\nFigure 18\n\
                    Open in figure viewer\nPowerPoint\nF measure of the training data\
                    \ samples for all the classifiers.\nDetails are in the caption\
                    \ following the image\nFigure 19\nOpen in figure viewer\nPowerPoint\n\
                    F measure of the testing data samples for all the classifiers.\n\
                    Figures 20 and 21 show the performance of eRBM, sRBM, decision\
                    \ tree, SVM, and KNN for both training and testing data samples\
                    \ in terms of recall. The eRBM model gives 0.9989 value of recall\
                    \ for dataset 2 in case training samples followed by dataset 1\
                    \ and dataset 3 for which the model gave the recall values of\
                    \ 0.9912 and 0.9376, respectively. In the same way, most of the\
                    \ other models gave better results for dataset 2 than the other\
                    \ two considered datasets. Keeping in consideration the values\
                    \ of recall for all the models and datasets, the highest value\
                    \ has been reported by the proposed eRBM models showing the strength\
                    \ of the enhancement introduced in the operational procedure of\
                    \ the RBM. Additionally, some fluctuations can be observed in\
                    \ the values of recall for KNN, SVM, decision tree, and standard\
                    \ RBM in case of all three datasets. There are similar observations\
                    \ in the values of recall for the testing dataset as well.\n\n\
                    Details are in the caption following the image\nFigure 20\nOpen\
                    \ in figure viewer\nPowerPoint\nF recall of the training data\
                    \ samples for all the classifiers.\nDetails are in the caption\
                    \ following the image\nFigure 21\nOpen in figure viewer\nPowerPoint\n\
                    F measure of the testing data samples for all the classifiers.\n\
                    Resultantly, considering all the performance evaluation parameters\
                    \ for all classifiers and three datasets, it can be concluded\
                    \ that the proposed eRBM gives better performance than standard\
                    \ RBM, KNN, decision tree, and SVM in case of both training and\
                    \ testing data samples.\n\n8. Conclusion\nIn this paper, enhanced\
                    \ RBM has been formulated to detect pneumonia. There are some\
                    \ drawbacks of the restricted Boltzmann machine which have been\
                    \ eradicated. Although different machines and deep learning techniques\
                    \ have been directed for pneumonia detection, but still, we have\
                    \ to accurate and amplify the accuracy of these techniques. Most\
                    \ correspondents have evaluated normal and abnormal pneumonia\
                    \ whatever it exists or not but could not be differentiated from\
                    \ bacterial and viral pneumonia. We have wiped out these imperfections\
                    \ and upgraded the preciseness of enhanced RBM through the model.\
                    \ Three datasets have been considered in the experimentation for\
                    \ perfectly evaluating the performance of the proposed model.\
                    \ The performance of the model has been evaluated using classification\
                    \ accuracy, specificity, precision, recall, and F1-score for all\
                    \ three datasets and has been compared with standard RBM, decision\
                    \ tree, SVM, and KNN. Although many fluctuations can be seen in\
                    \ the results of all classification models but the highest performance\
                    \ is that of the proposed enhanced RBM showing the strength of\
                    \ the enhancement introduced in the operational procedure of the\
                    \ standard RBM, this developed model can be implemented for using\
                    \ other datasets with other diseases and other similar scenarios\
                    \ which is left as future work of the proposed model.\n\nDisclosure\n\
                    The authors hereby confirm that the paper results are not clinical\
                    \ results based on clinical trials; instead, it is a computer-based\
                    \ study, in which we have trained a machine learning model using\
                    \ chest x-ray images. Therefore, there is no need of a trial registration\
                    \ number.\n\nConflicts of Interest\nNo potential conflicts of\
                    \ interest have been declared by the authors.\n\nAcknowledgments\n\
                    The authors are grateful to the Deanship of Scientific Research,\
                    \ King Saud University for funding through Vice Deanship of Scientific\
                    \ Research Chairs."
      responses:
        200:
          description: A successful article analysis, including tortured phrases IF
            present. Empty if no tortured phrases found.
          content:
            application/json:
              schema:
                $ref: '#/definitions/TorturedPhrasesApiResponse'
          examples:
            application/json:
              result:
              - rule:
                  torturedPhraseFingerprint: component extraction
                  expectedText: feature extraction
                phrasesFound:
                - position: 6899
                  match: component extraction
              - rule:
                  torturedPhraseFingerprint: neural organization
                  expectedText: neural network
                phrasesFound:
                - position: 29188
                  match: neural organization
              - rule:
                  torturedPhraseFingerprint: bosom   AND   breast
                  expectedText: breast
                phrasesFound:
                - position: 21442
                  match: breast
                - position: 21634
                  match: bosom
        400:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'INVALID_ARGUMENT: API key not valid. Please pass a valid API
                key.

                '
              code: 400
        401:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'UNAUTHENTICATED: Method doesn''t allow unregistered callers
                (callers without established identity). Please use API Key or other
                form of API consumer identity to call this API.

                '
              code: 401
  /argos/api/v1/references:
    post:
      tags:
      - reference analysis
      summary: Analyze the references of a scientific article
      description: "This operation allows users to analyze the references of a scientific\
        \ article by providing a list of DOIs. \nThe analysis includes checking if\
        \ each reference is retracted, has an expression of concern, is a retraction\
        \ note, \nand evaluates its risk level. Optionally performs a self-citation\
        \ analysis when authors are provided.\n"
      operationId: references
      requestBody:
        description: A list of DOIs to analyze
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                references:
                  type: array
                  items:
                    type: string
                    format: uri
                  description: A list of reference DOIs to be analyzed.
                  example:
                  - https://doi.org/example-doi-1
                  - https://doi.org/example-doi-2
                  - https://doi.org/non-existing-doi
                authors:
                  type: array
                  description: Optional list of authors to perform self-citation analysis.
                    If not provided, the self-citation analysis will not be performed.
                  items:
                    $ref: '#/definitions/ActorDefinition'
                  example:
                  - fullname: Author 1 Fullname
                    orcid: https://orcid.org/0000-0001-2345-6789
                  - fullname: Author 2 Fullname
                    openAlexId: https://openalex.org/A123456789
                  - fullname: Author 3 Fullname
      responses:
        200:
          description: A successful reference analysis
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/definitions/ReferenceAnalysisResponse'
          examples:
            application/json:
            - referenceDoi: https://doi.org/example-doi-1
              doiFound: true
              likelyHallucinated: false
              analysis:
                isRetracted: true
                hasExpressionOfConcern: false
                isRetractionNote: false
                isHighRisk: false
                isMediumRisk: false
                selfCitationAnalysis:
                  analysisPerformed: true
                  selfCitationsFound: true
                  authorsSelfCiting:
                  - fullname: Author 1 Fullname
                    orcid: https://orcid.org/0000-0001-2345-6789
            - referenceDoi: https://doi.org/example-doi-2
              doiFound: true
              likelyHallucinated: false
              analysis:
                isRetracted: false
                hasExpressionOfConcern: false
                isRetractionNote: false
                isHighRisk: false
                isMediumRisk: true
                selfCitationAnalysis:
                  analysisPerformed: true
                  selfCitationsFound: false
                  authorsSelfCiting: []
            - referenceDoi: https://doi.org/non-existing-doi
              doiFound: false
              likelyHallucinated: true
              analysis: null
        400:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'INVALID_ARGUMENT: API key not valid. Please pass a valid API
                key.

                '
              code: 400
        401:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'UNAUTHENTICATED: Method doesn''t allow unregistered callers
                (callers without established identity). Please use API Key or other
                form of API consumer identity to call this API.

                '
              code: 401
  /argos/api/v1/test:
    get:
      description: Test Endpoint to allow you to verify that you are sending correctly
        the API Keys from your client
      operationId: test
      produces:
      - application/json
      tags:
      - development
      responses:
        200:
          description: 'Success. Your client is propagating the API Keys correctly

            '
          schema:
            $ref: '#/definitions/Successresponse'
          examples:
            application/json:
              message: Test API Gateway passed
        400:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'INVALID_ARGUMENT: API key not valid. Please pass a valid API
                key.

                '
              code: 400
        401:
          description: Failure. Your client is NOT propagating the API Keys correctly.
          schema:
            $ref: '#/definitions/Test40xresponse'
          examples:
            application/json:
              message: 'UNAUTHENTICATED: Method doesn''t allow unregistered callers
                (callers without established identity). Please use API Key or other
                form of API consumer identity to call this API.

                '
              code: 401
responses:
  Unauthorized:
    description: Failure. Your client is NOT propagating the API Keys correctly. Make
      sure an x-api-key header is setup on your request and the value matches the
      one Scitility has provided you
    schema:
      $ref: '#/definitions/Test40xresponse'
    examples:
      application/json:
        message: 'UNAUTHENTICATED: Method doesn''t allow unregistered callers (callers
          without established identity). Please use API Key or other form of API consumer
          identity to call this API.

          '
        code: 401
definitions:
  Successresponse:
    type: object
    properties:
      message:
        type: string
  Test40xresponse:
    type: object
    properties:
      message:
        type: string
      code:
        type: integer
  Test404response:
    type: object
    properties:
      message:
        type: string
  SingleAuthorProfileResponse:
    type: object
    properties:
      metadata:
        type: object
        properties:
          timestamp:
            type: string
            description: Query execution timestamp. The data returned in this response
              reflects the knowledge of Argos at this point in time.
            format: date-time
          parameters:
            type: object
            description: Map of strings with the parameters used as inputs
            additionalProperties:
              type: string
          resultCount:
            description: Number of author profiles returned. Either 1 or 0.
            type: integer
      data:
        $ref: '#/definitions/AuthorProfile'
  MultipleAuthorProfileResponse:
    type: object
    properties:
      metadata:
        type: object
        properties:
          timestamp:
            type: string
            description: Query execution timestamp. The data returned in this response
              reflects the knowledge of Argos at this point in time.
            format: date-time
          parameters:
            type: object
            description: Map of strings with the parameters used as inputs
            additionalProperties:
              type: string
          resultCount:
            description: Number of author profiles returned. 0 or more.
            type: integer
      data:
        type: array
        items:
          $ref: '#/definitions/AuthorProfile'
  SelfCitingAuthorDefinition:
    type: object
    required:
    - fullname
    properties:
      fullname:
        type: string
        description: Full name of the author as specified in the request.
      orcid:
        type: string
        format: uri
        description: Optional ORCID identifier. Echoed from the request.
  AuthorProfile:
    type: object
    properties:
      ids:
        type: object
        properties:
          openAlexId:
            description: Author OpenAlex ID, unique identifier of the equivalent Author
              Profile in OpenAlex. For more information https://docs.openalex.org/api-entities/authors
            type: string
            format: uri
          orcid:
            description: Unique identifier of the equivalent Author Profile in Orcid.
              For more information see https://support.orcid.org/hc/en-us/articles/360006897674-Structure-of-the-ORCID-Identifier#:~:text=When%20stored%2C%20the%20ORCID%20iD,xxxx%2Dxxxx%2Dxxxx).
            type: string
            format: uri
      displayName:
        type: string
        description: Full name of the Author
      displayNameAlternatives:
        type: array
        items:
          type: string
        description: Alternative names that have been found on the work attributed
          to the Author
      institutions:
        type: array
        items:
          type: string
        description: Display name of the institutions that the Author has been affiliated
          with (limited to 10 institutions maximum)
      worksCount:
        type: integer
        description: Number of works attributed to the author. Refreshed once per
          month. Should be taking as an indication and not a precise number.
      citedByCount:
        type: integer
        description: Number of citations to works attributed to the author. Refreshed
          once per month. Should be taking as an indication and not a precise number.
      hIndex:
        type: integer
        description: Author's H-Index. Refreshed once per month. Should be taking
          as an indication and not a precise number.
      retractedWorksCount:
        type: integer
        description: Number of retracted works attributed to the Author. This number
          includes both retractions AND expressions of concern.
      retractedWorks:
        type: array
        items:
          $ref: '#/definitions/RetractedWork'
  ActorDefinition:
    type: object
    required:
    - fullname
    properties:
      fullname:
        type: string
        description: Full name of the author.
      orcid:
        type: string
        format: uri
        description: Optional ORCID identifier for the author. When available, please
          provide it as it will improve the performance of the self-citation analysis.
      openAlexId:
        type: string
        format: uri
        description: Optional OpenAlex ID for the author. When available, please provide
          it as it will improve the performance of the self-citation analysis.
  RetractedWork:
    type: object
    properties:
      title:
        type: string
        description: Article Title
      journal:
        type: string
        description: Display name of the Journal where the article was published
      publisher:
        type: string
        description: Publisher display name
      authors:
        type: array
        description: Array of Author's full names
        items:
          type: string
      originalPaperDoi:
        type: string
        description: URI pointing to the original article / Original DOI
        format: uri
      retractionDoi:
        type: string
        description: (Optional) URI pointing to the retraction note / Retraction DOI
        format: uri
      originalPaperDate:
        type: string
        description: Publication date
        format: date
      retractionDate:
        type: string
        description: (Optional) Retraction date, if known
        format: date
      retractionNature:
        type: string
        description: 'One of the following values: "Expression of concern", "Retraction"

          '
      reasons:
        type: array
        description: '(Optional) If known, reasons for the retraction. Eg: Paper Mill,
          Image Manipulation, etc.

          '
        items:
          type: string
      notes:
        type: string
        description: (Optional) Additional notes
      source:
        type: string
        description: Source used by Argos to ingest this data
      highRisk:
        type: boolean
        description: Whether Argos considers this retraction to be High Risk or just
          a normal retraction.
  SelfCitationAnalysis:
    type: object
    properties:
      analysisPerformed:
        type: boolean
        description: True if the self-citation analysis was performed (i.e., authors
          were provided in the request).
      selfCitationsFound:
        type: boolean
        description: True if at least one self-citation was found for the provided
          authors and this particular article.
      authorsSelfCiting:
        type: array
        description: List of authors who were identified as self-citing for this particular
          article.
        items:
          $ref: '#/definitions/SelfCitingAuthorDefinition'
  ReferenceAnalysisResponse:
    type: object
    properties:
      referenceDoi:
        type: string
        format: uri
        description: The DOI URL of the reference being analyzed.
      doiFound:
        type: boolean
        description: Indicates whether the DOI was found and resolvable.
      likelyHallucinated:
        type: boolean
        description: Indicates whether the reference is likely hallucinated. If the
          reference is marked as likely hallucinated, with high certainty the DOI
          does not exist and it is likely a construction of an Artificial Intelligence
          Model. The flag likelyHallucinated could be true only if the DOI is not
          found. The flag will always be false if the DOI is known to Argos.
      analysis:
        type: object
        nullable: true
        description: The result of the reference analysis. Will be null if `doiFound`
          is false.
        properties:
          isRetracted:
            type: boolean
            description: True if the article has been formally retracted.
          hasExpressionOfConcern:
            type: boolean
            description: True if the article has an expression of concern issued by
              the publisher.
          isRetractionNote:
            type: boolean
            description: True if the reference is a retraction notice rather than
              a regular article.
          isHighRisk:
            type: boolean
            description: True if the reference is assessed as high-risk by Argos.
          isMediumRisk:
            type: boolean
            description: True if the reference is assessed as medium-risk by Argos.
          selfCitationAnalysis:
            $ref: '#/definitions/SelfCitationAnalysis'
            description: Self-citation analysis results.
  TorturedPhrasesApiResponse:
    type: object
    properties:
      result:
        type: array
        items:
          $ref: '#/definitions/ResultItem'
        description: Tortured phrases found. Empty if none has been found.
    required:
    - result
  ResultItem:
    type: object
    properties:
      rule:
        $ref: '#/definitions/Rule'
      phrasesFound:
        type: array
        items:
          $ref: '#/definitions/PhraseFound'
    required:
    - rule
    - phrasesFound
  Rule:
    type: object
    properties:
      torturedPhraseFingerprint:
        type: string
        description: The fingerprint of the tortured phrase. It's a rule that can
          contain logical operators like AND, OR, NOT.
      expectedText:
        type: string
        description: The original phrase present in genuine scientific literature
          that led to the tortured phrase above.
    required:
    - torturedPhraseFingerprint
    - expectedText
  PhraseFound:
    type: object
    properties:
      position:
        type: integer
        description: position where we have found one of the components of the tortured
          phrases fingerprint.
      match:
        type: string
        description: the exact match found in the fulltext.
    required:
    - position
    - match
